{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this file and then run an experiment\n",
    "# Import modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import importlib\n",
    "import pickle  # Use this to save results so we don't need to rerun experiments\n",
    "rf = importlib.import_module(\"random-forests\")\n",
    "misclass_rate = rf.random_forests.misclassification_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all datasets to use\n",
    "mushroom = np.loadtxt(\"agaricus-lepiota.data\", dtype=str, delimiter=\",\")\n",
    "wine = np.loadtxt(\"wine.data\", delimiter=\",\")\n",
    "iris = np.loadtxt(\"iris_csv.csv\", dtype=str, delimiter=\",\")\n",
    "heart = np.loadtxt(\"processed.cleveland.data\", dtype=str, delimiter=\",\")\n",
    "titanic = pd.read_csv(\"titanic.csv\").drop(columns=[\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data\n",
    "def str_in_arr(arr, str):\n",
    "    return not np.isin(str, arr)\n",
    "barr_mushroom = np.apply_along_axis(str_in_arr, 1, mushroom, \"?\")\n",
    "mushroom = mushroom[barr_mushroom, :]\n",
    "barr_heart = np.apply_along_axis(str_in_arr, 1, heart, \"?\")\n",
    "heart = heart[barr_heart, :]\n",
    "heart = heart.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate into data and labels\n",
    "iris_data = iris[1:, :4].astype(float)\n",
    "iris_labels = iris[1:, 4]\n",
    "wine_data = wine[:, 1:]\n",
    "wine_labels = wine[:, 0].astype(int)\n",
    "heart_data = heart[:, :-1]\n",
    "heart_labels = heart[:, -1].astype(int)\n",
    "# Turn heart_labels into array of 0, 1.\n",
    "# 1 indicates presence of any type of heart disease, 0 indicates no presence\n",
    "heart_labels_barr = heart_labels >= 1\n",
    "heart_labels[heart_labels_barr] = 1\n",
    "mushroom_data = mushroom[:, 1:]\n",
    "mushroom_labels = mushroom[:, 0]\n",
    "titanic_data = titanic.loc[:, titanic.columns!=\"Survived\"].to_numpy()  # feature_type: complex\n",
    "titanic_labels = titanic[\"Survived\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record the feature types\n",
    "iris_ftype = \"continuous\"\n",
    "heart_ftype = np.array([0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1])\n",
    "wine_ftype = \"continuous\"\n",
    "mushroom_ftype = \"categorical\"\n",
    "titanic_ftype = np.array([1, 1, 0, 0, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed so test train split it always the same for all tests\n",
    "np.random.seed(1)\n",
    "datasets = {\"iris\": (*train_test_split(iris_data, iris_labels, stratify=iris_labels), \"continuous\"),\n",
    "            \"wine\": (*train_test_split(wine_data, wine_labels, stratify=wine_labels), \"continuous\"),\n",
    "            \"heart\": (*train_test_split(heart_data, heart_labels, stratify=heart_labels), heart_ftype),\n",
    "            \"mushroom\": (*train_test_split(mushroom_data, mushroom_labels, stratify=mushroom_labels), \"categorical\"),\n",
    "            \"titanic\": (*train_test_split(titanic_data, titanic_labels, stratify=titanic_labels), titanic_ftype)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m         random_forest \u001b[39m=\u001b[39m rf\u001b[39m.\u001b[39mRandomForest(n_trees\u001b[39m=\u001b[39mntree, n_candidates\u001b[39m=\u001b[39mn_cand, max_depth\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m     16\u001b[0m         \u001b[39m# print(X_train)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m         \u001b[39m# print(y_train)\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m         random_forest\u001b[39m.\u001b[39;49mfit(X_train, y_train, feature_type\u001b[39m=\u001b[39;49mftype, m_features\u001b[39m=\u001b[39;49mm_feats)\n\u001b[0;32m     19\u001b[0m         result[i, j] \u001b[39m=\u001b[39m misclass_rate(random_forest\u001b[39m.\u001b[39mpredict(X_test), y_test)\n\u001b[0;32m     20\u001b[0m results[dataset] \u001b[39m=\u001b[39m result\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\random_forests.py:58\u001b[0m, in \u001b[0;36mRandomForest.fit\u001b[1;34m(self, X, y, feature_type, m_features)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[39m# Bootstrap sample.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m X_bootstrap, y_bootstrap \u001b[39m=\u001b[39m bootstrap(X, y)\n\u001b[1;32m---> 58\u001b[0m tree\u001b[39m.\u001b[39;49mfit(X_bootstrap, y_bootstrap, feature_type, m_features)\n\u001b[0;32m     59\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforest\u001b[39m.\u001b[39mappend(tree)\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:93\u001b[0m, in \u001b[0;36mDecisionTree.fit\u001b[1;34m(self, X, y, feature_type, m_features)\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_type \u001b[39m=\u001b[39m feature_type\n\u001b[0;32m     92\u001b[0m \u001b[39m# Grow the decision tree.\u001b[39;00m\n\u001b[1;32m---> 93\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow(X, y)\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:132\u001b[0m, in \u001b[0;36mDecisionTree._grow\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    128\u001b[0m right_idx \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mleft_idx\n\u001b[0;32m    129\u001b[0m \u001b[39m# Increment depth and call _grow() recursively.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# left_data = X[left_idx]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m# right_data = X[right_idx]\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m left_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow(X[left_idx], y[left_idx], depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    133\u001b[0m right_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow(X[right_idx], y[right_idx], depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m Node(feature, threshold, left_node, right_node)\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:132\u001b[0m, in \u001b[0;36mDecisionTree._grow\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    128\u001b[0m right_idx \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mleft_idx\n\u001b[0;32m    129\u001b[0m \u001b[39m# Increment depth and call _grow() recursively.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# left_data = X[left_idx]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m# right_data = X[right_idx]\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m left_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow(X[left_idx], y[left_idx], depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    133\u001b[0m right_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow(X[right_idx], y[right_idx], depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m Node(feature, threshold, left_node, right_node)\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:133\u001b[0m, in \u001b[0;36mDecisionTree._grow\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m# Increment depth and call _grow() recursively.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# left_data = X[left_idx]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m# right_data = X[right_idx]\u001b[39;00m\n\u001b[0;32m    132\u001b[0m left_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow(X[left_idx], y[left_idx], depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m right_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow(X[right_idx], y[right_idx], depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m Node(feature, threshold, left_node, right_node)\n",
      "    \u001b[1;31m[... skipping similar frames: DecisionTree._grow at line 132 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:133\u001b[0m, in \u001b[0;36mDecisionTree._grow\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m# Increment depth and call _grow() recursively.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# left_data = X[left_idx]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m# right_data = X[right_idx]\u001b[39;00m\n\u001b[0;32m    132\u001b[0m left_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow(X[left_idx], y[left_idx], depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m right_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow(X[right_idx], y[right_idx], depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m Node(feature, threshold, left_node, right_node)\n",
      "    \u001b[1;31m[... skipping similar frames: DecisionTree._grow at line 132 (15 times), DecisionTree._grow at line 133 (1 times)]\u001b[0m\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:132\u001b[0m, in \u001b[0;36mDecisionTree._grow\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    128\u001b[0m right_idx \u001b[39m=\u001b[39m \u001b[39m~\u001b[39mleft_idx\n\u001b[0;32m    129\u001b[0m \u001b[39m# Increment depth and call _grow() recursively.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# left_data = X[left_idx]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m# right_data = X[right_idx]\u001b[39;00m\n\u001b[1;32m--> 132\u001b[0m left_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow(X[left_idx], y[left_idx], depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    133\u001b[0m right_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow(X[right_idx], y[right_idx], depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m Node(feature, threshold, left_node, right_node)\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:133\u001b[0m, in \u001b[0;36mDecisionTree._grow\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m# Increment depth and call _grow() recursively.\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# left_data = X[left_idx]\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[39m# right_data = X[right_idx]\u001b[39;00m\n\u001b[0;32m    132\u001b[0m left_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_grow(X[left_idx], y[left_idx], depth\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m--> 133\u001b[0m right_node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_grow(X[right_idx], y[right_idx], depth\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m Node(feature, threshold, left_node, right_node)\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:121\u001b[0m, in \u001b[0;36mDecisionTree._grow\u001b[1;34m(self, X, y, depth)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[39mreturn\u001b[39;00m Node(data\u001b[39m=\u001b[39mmajority_vote(y))\n\u001b[0;32m    119\u001b[0m \u001b[39m# Find the best splitting feature and threshhold\u001b[39;00m\n\u001b[0;32m    120\u001b[0m \u001b[39m# using greedy approach.\u001b[39;00m\n\u001b[1;32m--> 121\u001b[0m feature, threshold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cutpoint(X, y, v_cols)\n\u001b[0;32m    122\u001b[0m \u001b[39m# Split the data using the best cutpoint.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m# Create two boolean arrays to slice left and right data.\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeature_type[feature]:  \u001b[39m# If categorical.\u001b[39;00m\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:160\u001b[0m, in \u001b[0;36mDecisionTree._cutpoint\u001b[1;34m(self, X, y, v_cols)\u001b[0m\n\u001b[0;32m    157\u001b[0m     score, threshold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_categorical(X, y, feature)\n\u001b[0;32m    158\u001b[0m \u001b[39m# Continuous split.\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     score, threshold \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_split_continuous(X, y, feature)\n\u001b[0;32m    161\u001b[0m \u001b[39m# Update best feature and threshold\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mif\u001b[39;00m score \u001b[39m<\u001b[39m best_score:\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:175\u001b[0m, in \u001b[0;36mDecisionTree._split_continuous\u001b[1;34m(self, X, y, feature)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[39m# Randomly choose a threshold.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m threshold \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39muniform(lo, hi)\n\u001b[1;32m--> 175\u001b[0m score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_criterion(X_col, y, feature, threshold)\n\u001b[0;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m score, threshold\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:211\u001b[0m, in \u001b[0;36mDecisionTree._criterion\u001b[1;34m(self, X_col, y, feature, threshold)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mgini\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    210\u001b[0m     left_score \u001b[39m=\u001b[39m gini_index(y[left_idx])\n\u001b[1;32m--> 211\u001b[0m     right_score \u001b[39m=\u001b[39m gini_index(y[right_idx])\n\u001b[0;32m    212\u001b[0m     \u001b[39m# Sum.\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     rt \u001b[39m=\u001b[39m left_score \u001b[39m+\u001b[39m right_score\n",
      "File \u001b[1;32m~\\M2R\\M2R-random-forests\\random-forests\\decision_trees.py:237\u001b[0m, in \u001b[0;36mgini_index\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Return the gini index for labels `y`.\"\"\"\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m# G = sum(p_m_k(1 - p_m_k)), 1 <= k <= K\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m ps \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(y, return_counts\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)[\u001b[39m1\u001b[39m] \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y)\n\u001b[0;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39msum(ps \u001b[39m*\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m ps))\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\grave\\M2R\\M2R_venv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:274\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[0;32m    272\u001b[0m ar \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masanyarray(ar)\n\u001b[0;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[0;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39;49mequal_nan)\n\u001b[0;32m    276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\grave\\M2R\\M2R_venv\\Lib\\site-packages\\numpy\\lib\\arraysetops.py:363\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts, equal_nan)\u001b[0m\n\u001b[0;32m    361\u001b[0m     ret \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (inv_idx,)\n\u001b[0;32m    362\u001b[0m \u001b[39mif\u001b[39;00m return_counts:\n\u001b[1;32m--> 363\u001b[0m     idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate(np\u001b[39m.\u001b[39;49mnonzero(mask) \u001b[39m+\u001b[39m ([mask\u001b[39m.\u001b[39msize],))\n\u001b[0;32m    364\u001b[0m     ret \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (np\u001b[39m.\u001b[39mdiff(idx),)\n\u001b[0;32m    365\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
      "File \u001b[1;32m<__array_function__ internals>:177\u001b[0m, in \u001b[0;36mnonzero\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "# Create an example plot for n_trees = 1-20 with error bars\n",
    "ntrees = np.arange(1, 21)\n",
    "# number of experiments to run for each parameter choice\n",
    "nexp = 10\n",
    "results = {}\n",
    "for dataset in datasets.keys():\n",
    "    X_train, X_test, y_train, y_test, ftype = datasets[dataset]\n",
    "    result = np.empty((len(ntrees), nexp), dtype=float)\n",
    "    m_feats = int(np.floor(np.sqrt(X_train.shape[1])))\n",
    "    n_cand = 3*m_feats\n",
    "    # print(dataset)\n",
    "    for i, ntree in enumerate(ntrees):\n",
    "        for j in range(nexp):\n",
    "            random_forest = rf.RandomForest(n_trees=ntree, n_candidates=n_cand, max_depth=100)\n",
    "            # print(X_train)\n",
    "            # print(y_train)\n",
    "            random_forest.fit(X_train, y_train, feature_type=ftype, m_features=m_feats)\n",
    "            result[i, j] = misclass_rate(random_forest.predict(X_test), y_test)\n",
    "    results[dataset] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an example plot for n_trees = 1-20 with error bars\n",
    "ntrees = np.arange(1, 21)\n",
    "# number of experiments to run for each parameter choice\n",
    "nexp = 10\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"iris\"\n",
    "X_train, X_test, y_train, y_test, ftype = datasets[dataset]\n",
    "result = np.empty((len(ntrees), nexp), dtype=float)\n",
    "m_feats = int(np.floor(np.sqrt(X_train.shape[1])))\n",
    "n_cand = 3*m_feats\n",
    "np.random.seed(1)\n",
    "for i, ntree in enumerate(ntrees):\n",
    "    for j in range(nexp):\n",
    "        random_forest = rf.RandomForest(n_trees=ntree, n_candidates=n_cand, max_depth=100)\n",
    "        random_forest.fit(X_train, y_train, feature_type=ftype, m_features=m_feats)\n",
    "        result[i, j] = misclass_rate(random_forest.predict(X_test), y_test)\n",
    "results[dataset] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"wine\"\n",
    "X_train, X_test, y_train, y_test, ftype = datasets[dataset]\n",
    "result = np.empty((len(ntrees), nexp), dtype=float)\n",
    "m_feats = int(np.floor(np.sqrt(X_train.shape[1])))\n",
    "n_cand = 3*m_feats\n",
    "np.random.seed(1)\n",
    "for i, ntree in enumerate(ntrees):\n",
    "    for j in range(nexp):\n",
    "        random_forest = rf.RandomForest(n_trees=ntree, n_candidates=n_cand, max_depth=100)\n",
    "        random_forest.fit(X_train, y_train, feature_type=ftype, m_features=m_feats)\n",
    "        result[i, j] = misclass_rate(random_forest.predict(X_test), y_test)\n",
    "results[dataset] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"heart\"\n",
    "X_train, X_test, y_train, y_test, ftype = datasets[dataset]\n",
    "result = np.empty((len(ntrees), nexp), dtype=float)\n",
    "m_feats = int(np.floor(np.sqrt(X_train.shape[1])))\n",
    "n_cand = 3*m_feats\n",
    "np.random.seed(1)\n",
    "for i, ntree in enumerate(ntrees):\n",
    "    for j in range(nexp):\n",
    "        random_forest = rf.RandomForest(n_trees=ntree, n_candidates=n_cand, max_depth=100)\n",
    "        random_forest.fit(X_train, y_train, feature_type=ftype, m_features=m_feats)\n",
    "        result[i, j] = misclass_rate(random_forest.predict(X_test), y_test)\n",
    "results[dataset] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['iris', 'wine', 'heart'])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = open(\"vary_n_trees\", \"wb\")\n",
    "pickle.dump(results, po)\n",
    "po.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"titanic\"\n",
    "X_train, X_test, y_train, y_test, ftype = datasets[dataset]\n",
    "result = np.empty((len(ntrees), nexp), dtype=float)\n",
    "m_feats = int(np.floor(np.sqrt(X_train.shape[1])))\n",
    "n_cand = 3*m_feats\n",
    "np.random.seed(1)\n",
    "for i, ntree in enumerate(ntrees):\n",
    "    for j in range(nexp):\n",
    "        random_forest = rf.RandomForest(n_trees=ntree, n_candidates=n_cand, max_depth=100)\n",
    "        random_forest.fit(X_train, y_train, feature_type=ftype, m_features=m_feats)\n",
    "        result[i, j] = misclass_rate(random_forest.predict(X_test), y_test)\n",
    "results[dataset] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mushroom\"\n",
    "X_train, X_test, y_train, y_test, ftype = datasets[dataset]\n",
    "result = np.empty((len(ntrees), nexp), dtype=float)\n",
    "m_feats = int(np.floor(np.sqrt(X_train.shape[1])))\n",
    "n_cand = 3*m_feats\n",
    "np.random.seed(1)\n",
    "for i, ntree in enumerate(ntrees):\n",
    "    for j in range(nexp):\n",
    "        random_forest = rf.RandomForest(n_trees=ntree, n_candidates=n_cand, max_depth=100)\n",
    "        random_forest.fit(X_train, y_train, feature_type=ftype, m_features=m_feats)\n",
    "        result[i, j] = misclass_rate(random_forest.predict(X_test), y_test)\n",
    "results[dataset] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"mushroom\"][1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ntree=1\n",
    "np.random.seed(1)\n",
    "random_forest = rf.RandomForest(n_trees=20, n_candidates=n_cand, max_depth=100)\n",
    "random_forest.fit(X_train, y_train, feature_type=ftype, m_features=m_feats)\n",
    "misclass_rate(random_forest.predict(X_test), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(random_forest.predict(X_test) == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['iris', 'wine', 'heart', 'titanic', 'mushroom'])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = open(\"vary_n_trees.pickle\", \"wb\")\n",
    "pickle.dump(results, po)\n",
    "po.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "po = open(\"vary_n_trees.pickle\", \"rb\")\n",
    "r2 = pickle.load(po)\n",
    "po.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for key in results.keys():\n",
    "    print(np.all(r2[key] == results[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M2R_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
